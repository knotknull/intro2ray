
Ray AI Libraries


http://localhost:8888/notebooks/1_AI_Libs_Intro.ipynb


## Lesson 1:  Ray AI Libraries

5 parts to Ray 


[ Ray Data ] [ Ray Train ] [ Ray Tune ] [ Ray Serve ]
[ -------------------- Ray Core ------------------- ]


Key parts in the above notebook: 


## Read the dataset
dataset = ray.data.read_parquet("s3://anonymous@anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet")

## Split the dataset into training and validation sets
train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)


## Define the trainer
trainer = XGBoostTrainer(
    label_column="is_big_tip",
    scaling_config=ScalingConfig(num_workers=4, use_gpu=True),
    params={"objective": "binary:logistic"},
    datasets={"train": train_dataset, "valid": valid_dataset},
    run_config=RunConfig(storage_path="/mnt/cluster_storage/"),
)

## Fit the trainer
result = trainer.fit()


## Define the tuner
tuner = Tuner(
    trainer,
    param_space={"params": {"max_depth": tune.randint(2, 12)}},
    tune_config=TuneConfig(num_samples=3, metric="valid-logloss", mode="min"),
    run_config=RunConfig(storage_path="/mnt/cluster_storage/"),
)

## Fit the tuner and get the best checkpoint
checkpoint = tuner.fit().get_best_result().checkpoint

## Create an offline predictor 
class OfflinePredictor:
        # Load expensive state

## Apply the predictor to the validation dataset 
valid_dataset_inputs = valid_dataset.drop_columns(['is_big_tip'])
predicted_probabilities = valid_dataset_inputs.map_batches(OfflinePredictor, concurrency=2)

## Materialize a batch
predicted_probabilities.take_batch()

## Online prediction w/ Ray Serve
@serve.deployment
class OnlinePredictor:
    def __init__(self, checkpoint):
        ....
    async def __call__(self, request: Request) -> dict:
        # Handle HTTP request
        ....
    def predict(self, data: list[dict]) -> list[float]:
        # Make prediction
        ....

## Run the deployment
handle = serve.run(OnlinePredictor.bind(checkpoint=checkpoint))

## Get payload
valid_dataset_inputs = valid_dataset.drop_columns(["is_big_tip"])
sample_batch = valid_dataset_inputs.take_batch(1)
data = pd.DataFrame(sample_batch).to_json(orient="records")

## Send HTTP request
requests.post("http://localhost:8000/", json=data).json()


In overview the above:
 - gets parquet data and splits to train and valid subsets
 - sets a trainer and fits it 
 - sets a tuner  and fits it
 - creates an offline predictor
    - applies predictor to valid subset
    - gets prediction back
 - creates an online predictor with ray server
    - get a dataset from valid subset 
    - creates a dataframe and sends to online predictor







## Lesson 2:  Ray Train w/ PyTorch
http://localhost:8888/notebooks/2_Intro_Train.ipynb

Single GPU PyTorch fitting ResNet18 model to MNIST dataset
 - Training Process 

+------------------------------------------------------------------------+
|                                                                        |
|        +-----------------------------------------------------------+   |
|        |                                                           |   |
|        |                 +-----------------------------+           |   |
|        |                 v                             |           |   |
| [Data] |  [Model] --> [Forward] --> [Backward] --> [Update ]       |   |
|        |              [  Pass ]     [  Pass  ]     [Weights]   GPU |   |
|        |                                                           |   |
|        +-----------------------------------------------------------+   |
|                                                                        |
|                                                                        |
|                                                                   CPU  |
+------------------------------------------------------------------------+


The lesson takes you thru setting up data and a model to train on a local node and then 
how this functionality looks utilizing Ray and multiple workers and gpus

i.e. 
scaling_config = ScalingConfig(num_workers=2, use_gpu=True)


Distributed Data Parallel Training with Ray Train and PyTorch

+-----------------------------------------------------------------------------------+
|                               train.torch.prepare_model                           |
|         +---------------------------------------------------------------------+   |
|         |                                                                     |   |
|         |                 +-------------------------------------+             |   |
|         |                 v                                     |             |   |          train.report
| [Data]->|  [Model] --> [Forward] --> [Backward] --> [All   ] --> [Update ]    |   |
| [Shard] |    ^         [  Pass ]     [  Pass  ]     [Reduce] --> [Weights]    |   +------> [Model Checkpoint ]
|    |    |    |                                         ^                      |   |        [ and metrics     ]
|    |    |    |                                         |                GPU 0 |   |
|    |    +----+-----------------------------------------+----------------------+   |
|    |         |                                         |                          |
|    |       Sync                                      Sync                         |
| [Dataset]  initial state                             Gradients                    |
|    |         |                                          |                         |
|    |         |                                          |                         |
|    |    +----+-----------------------------------------------+----------------+   |
|    |    |    |                                          |                     |   |
|    |    |    v                                          v                     |   |
| [Data]->|  [Model] --> [Forward] --> [Backward] --> [ All  ] -->  [Update ]   |   |
| [Shard] |              [  Pass ]     [  Pass  ]     [Reduce] -->  [Weights]   |   |
|         |                 ^                                          |        |   |
|         |                 +------------------------------------------+        |   |
|         |                                                               GPU 1 |   |
|         +---------------------------------------------------------------------+   |
|                                                                                   |
|train.torch.prepare_data_loader                                                    |
|                                                                              CPU  |
+-----------------------------------------------------------------------------------+


The lesson takes you thru setting up data and a model to train on a local node and then 

## Lesson 3:  Ray Tune
notebooks/3_Intro_Tune.ipynb

Hyperparameter tuning library

MNIST Dataset : 28 x 28 grayscale (0=Black, 255=White) images of handwritten digits (0-9)

Training set: 60k images 
Test set    : 10k images 



## DataLoader from Torch

def build_data_loader(batch_size: int) -> torch.utils.data.DataLoader:
    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])
    train_data = MNIST(root="./data", train=True, download=True, transform=transform)
    data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)
    return data_loader


Train loop utilizes:
  - resnet18 (18 layer deep network)
  - training loop (train_loop_torch)
  - # of epochs,  batch size, learning rate (100000)
  - put model onto gpu (  model.to("cuda")  )




## train_loop with number of epochs, batch size and learn rate 
## 
def train_loop_torch(num_epochs: int = 2, batch_size: int = 128, lr: float = 1e-5):   
    criterion = CrossEntropyLoss()                  ## how to calculate loss actual vs. estimated

    model = resnet18()                              ## Resnet18 Model
    model.conv1 = torch.nn.Conv2d(
        1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False        ## first layer of Resnet18 model needs to be "swapped out"
    )
    model.to("cuda")                                        ## put model on GPU 
    data_loader = build_data_loader(batch_size)             ## load data
    optimizer = Adam(model.parameters(), lr=lr)             ## optimizer with model params

    for epoch in range(num_epochs):
        for images, labels in data_loader:                          ## loop thru images, labels
            images, labels = images.to("cuda"), labels.to("cuda")   ## put onto GPU
            outputs = model(images)                                 ## predict output
            loss = criterion(outputs, labels)                       ## calculate loss
            optimizer.zero_grad()                                   ## set optimizer state
            loss.backward()                                         ## backward propogate loss
            optimizer.step()                                        ## take optimization step

        # Report the metrics
        print(f"Epoch {epoch}, Loss: {loss}")





Can process be done better? 

Hyperparameter tuning is a computationally expensive task, and it will take a long time to run sequentially.

Ray Tune is a distributed hyperparameter tuning library that can help us speed up the process!





recap what actually happened here ?

tuner = tune.Tuner(
    trainable=train_my_simple_model,  # Training function or class to be tuned
    param_space={
        "a": tune.randint(0, 20),  # Hyperparameter: a
    },
    tune_config=tune.TuneConfig(
        metric="rmse",  # Metric to optimize (minimize)
        mode="min",     # Minimize the metric
        num_samples=5,  # Number of samples to try
    ),
)

results = tuner.fit()

A Tuner accepts:

    A training function or class which is specified by trainable
    A search space which is specified by param_space
    A metric to optimize which is specified by metric and the direction of optimization mode
    num_samples which correlates to the number of trials to run

tuner.fit then runs multiple trials in parallel, each with a different set of hyperparameters, and returns the 
best set of hyperparameters found.



by default:

    Each trial will run in a separate process and consume 1 CPU core.
    Ray Tune uses a search algorithm to decide which trials to run next.
    Ray Tune uses a scheduler to decide if/when to stop trials, or to prioritize certain trials over others.


tuner = tune.Tuner(
    # This is how to specify resources for your trainable function
    trainable=tune.with_resources(train_my_simple_model, {"cpu": 1}),
    param_space={"a": tune.randint(0, 20)},
    tune_config=tune.TuneConfig(
        mode="min",
        metric="rmse",
        num_samples=5, 
        # This search algorithm is a basic variation (i.e random/grid search) based on parameter space
        search_alg=tune.search.BasicVariantGenerator(), 
        # This scheduler is very simple: no early stopping, just run all trials in submission order
        scheduler=tune.schedulers.FIFOScheduler(), 
    ),
)
results = tuner.fit()

Ray Tune components 

   [ Search Spaces    ]   [ Trainables  Spaces      ]
   [ Which parameters ]   [ which objective to tune ] --+
                                                        |
                          [ Search Algorithms ]         +--------> [ Trials          ]--------> [ Search Algorithms ]
                          [ How to Tune       ]         |          [ Run experiments ]          [ How to Tune       ]
                                                        |
                          [ Schedulers   ]              |
                          [ When to Stop ]            --+






Hyperparameter tune the PyTorch model using Ray Tune

The first step is to move in all the PyTorch code into a function that we can pass to the trainable argument of the tune.run function.


def train_pytorch(config): # we change the function so it accepts a config dictionary
    criterion = CrossEntropyLoss()

    model = resnet18()
    model.conv1 = torch.nn.Conv2d(
        1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
    )
    model.to("cuda")

    optimizer = Adam(model.parameters(), lr=config["lr"])
    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])                            ## Ray specific
    train_data = MNIST(root="./data", train=True, download=True, transform=transform)       ## Ray specific
    data_loader = DataLoader(train_data, batch_size=config["batch_size"], shuffle=True, drop_last=True)  ## Ray specific

    for epoch in range(config["num_epochs"]):
        for images, labels in data_loader:
            images, labels = images.to("cuda"), labels.to("cuda")
            outputs = model(images)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        # Report the metrics using train.report instead of print
        train.report({"loss": loss.item()}                 ## Ray specific)




The second and third steps are the same as before. We define the tuner and run it by calling the fit method.

tuner = tune.Tuner(
    trainable=tune.with_resources(train_pytorch, {"gpu": 1}),   # Ray Tune: we will dedicate 1 GPU to each trial
    param_space={                                               # Ray Tune specific 
        "num_epochs": 1,
        "batch_size": 128,
        "lr": tune.loguniform(1e-4, 1e-1),
    },
    tune_config=tune.TuneConfig(
        mode="min",
        metric="loss",
        num_samples=2,
        search_alg=tune.search.BasicVariantGenerator(),
        scheduler=tune.schedulers.FIFOScheduler(),
    ),
)

results = tuner.fit()

best_result = results.get_best_result()
best_result.config





https://www.uber.com/blog/from-predictive-to-generative-ai/

https://engineering.atspotify.com/2023/02/unleashing-ml-innovation-at-spotify-with-ray/





## Lesson 4:  Ray Data
notebooks/4_Intro_Data.ipynb


Ray datasets are main abstraction for Ray Data


Use Datasets as a "last-mile bridge" from storage or ETL pipeline outputs to distributed applications and libraries in Ray. 
                               +----------------------------------------------+ 
[ DataFrame / Relational ]  ->  | [ Load Data / Last Mile ] -> [  ML      ]   |
[ Data Processing / ETL  ]      | [ Preprocessing         ]    [ Training ]   |
                                +---------------------------------------------+
                                            ^      Ray Cluster     ^
                                 Ray Data --+                      +---- Ray Train



Loading Data:
Datasets use Ray tasks to read data from remote storage.  When reading from file-based datasource (S3, GCS)
it creates a number of read tasks proportional to the number of CPUS in the cluster.

Each read task is assigned files and produces an output block: 

[ File 1 ] -->> [Read Task] -->> [ Block ]
[ File 2 ] -->> [Read Task] -->> [ Block ]
[ File 3 ] -->> [Read Task] -->> [ Block ]
[ File 4 ] -->> [Read Task] -->> [ Block ]

ray.data.read_csv(path)

# Sample

!aws s3 ls s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/
ds = ray.data.read_images("s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/", include_paths=True)
ds


NOTE: Ray  Data API  
https://docs.ray.io/en/latest/data/api/input_output.html


Datasets consist of blocks
 - a list of Ray object references to blocks 
    - numpy arrays

ray.data.Dataset
            |  "col"  | "col2"
------------|---------|-------------
   1 - 1000 | ObjRef(block1)  ------------->  pyarrow.Table [ num_rows=1000, schema={"col1", "col2"} ]  
1001 - 2000 | ObjRef(block2)  ------------->  pyarrow.Table [ num_rows=1000, schema={"col1", "col2"} ]  
2001 - 3000 | ObjRef(block3)  ------------->  pyarrow.Table [ num_rows=1000, schema={"col1", "col2"} ]  



each block is a pyarrow.Table with X rows and Schema

A dataset or individual block can be processed by Ray task or actor
NOTE: Using actors allows for expensive state initialization (e.g., for GPU-based tasks) to be cached.


 +----------------------------------------------------------------------------------------+
 |                                                                                        |
 |                         [ Actor Pool  ]      [ Actor Pool  ]                           |
 |  [ CPU Tasks     ]      [ GPU Tasks   ]      [ GPU Tasks   ]      [ CPU Tasks    ]     |                                                            |                                                                |                                                            |                                                             |                                                            |
 |  [S3 Get-> Resize] -+-> [ Segmentation] -+-> [ Segmentation] -+-> [ Write Result ]     |
 |  [S3 Get-> Resize]  |   [ Model       ]  |   [ Model       ]  |   [ Write Result ]     |                                                                                   |
 |                     |                    |                    |                        |
 |                     |                    |                    |                        |
 +---------------------|--------------------|--------------------|------------------------+
                       |                    |                    |          Ray Cluster
                       +--------------------+--------------------+
                                            |
                                Data streamed through memory        


Ray Tasks for stateless operations and Ray Actors for stateful operations

i.e. Load a large ML Model once and pass batches over it.
    - can execute data transformation on mix of GPUs and CPUS


map_batches allows for transformation on batches of data: 

def normalize(
    batch: dict[str, np.ndarray], min_: float, max_: float
) -> dict[str, np.ndarray]:
    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])
    batch["image"] = [transform(image) for image in batch["image"]]
    return batch


ds_normalized = ds.map_batches(normalize, fn_kwargs={"min_": 0, "max_": 255})
ds_normalized



Execution mode

Most transformations are lazy. They don't execute until you write a dataset to storage or decide to materialize/consume the dataset.

NOTE: To materialize a very small subset of the data, you can use the take_batch method.




Stateful transformations with actors

In cases like batch inference, you want to spin up a number of actor processes that are initialized once 
with your model and reused to process multiple batches.

To implement this, you can use the map_batches API with a "Callable" class method that implements:

    __init__: Initialize any expensive state.
    __call__: Perform the stateful transformation.

For example, we can implement a MNISTClassifier that:

    loads a pre-trained model from a local file
    accepts a batch of images and generates the predicted label


class MNISTClassifier:
    def __init__(self, local_path: str):
        self.model = torch.jit.load(local_path)
        self.model.to("cuda")
        self.model.eval()

    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:
        images = torch.tensor(batch["image"]).float().to("cuda")

        with torch.no_grad():
            logits = self.model(images).cpu().numpy()

        batch["predicted_label"] = np.argmax(logits, axis=1)
        return batch

# We download the model from s3 to an EFS storage
!aws s3 cp s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt /mnt/cluster_storage/model.pt

ds_preds = ds_normalized.map_batches(
    MNISTClassifier,
    fn_constructor_kwargs={"local_path": "/mnt/cluster_storage/model.pt"},
    num_gpus=0.1,
    concurrency=1,
    batch_size=100,
)

NOTE:  Call map_batches with MNISTClassifier Callable API class




Can materialize data set to ray object store distributed across cluster via materialize() 
NOTE; only use when you require full dataset to compute downstream outputs



Data Operations: Grouping, Aggregation and Shuffling


Use groupby() to generate batches by specific key followed by map_groups for transformation




# set ground truth label of picture
# 
def add_label(batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:
    batch["ground_truth_label"] = [int(path.split("/")[-2]) for path in batch["path"]]
    return batch

# set ground truth label of picture
#  predicted label vs ground truthe label  
#  
def compute_accuracy(group: dict[str, np.ndarray]) -> dict[str, np.ndarray]:
    return {
        "accuracy": [np.mean(group["predicted_label"] == group["ground_truth_label"])],
        "ground_truth_label": group["ground_truth_label"][:1],
    }


# create batches, grouped by groud truth label and then groups mapped to accuracy
ds_preds.map_batches(add_label).groupby("ground_truth_label").map_groups(compute_accuracy).to_pandas()


# Aggregates

Ray Data provides the following agg functions: 
- count
- max
- mean
- min
- sum
- std

ds_preds.map_batches(add_label).map_batches(compute_accuracy).mean(on="accuracy")


# Shuffling Data

Shuffle based on file reads


To randomly shuffle the ordering of input files before reading, call a read function that supports shuffling, 
such as `read_images()`, and use the shuffle="files" parameter.

ray.data.read_images("s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/", shuffle="files")


Shuffling block order

Randomizes the order of blocks in a dataset. Applying this operation alone doesn’t involve heavy computation and communication. 
However, it requires Ray Data to materialize all blocks in memory before applying the operation. Only use this option when your 
dataset is small enough to fit into the object store memory.

To perform block order shuffling, use randomize_block_order.

ds_randomized_blocks = ds_preds.randomize_block_order()
ds_randomized_blocks.materialize()


Shuffle all rows globally

To randomly shuffle all rows globally, call random_shuffle(). This is the slowest option for shuffle, 
and requires transferring data across network between workers. 
This option achieves the best randomness among all options but is expensive due to communication across cluster.

ds_randomized_rows = ds_preds.random_shuffle()
ds_randomized_rows.materialize()


# Persist data using Ray Data write functions 

ds_preds.write_parquet("/mnt/cluster_storage/mnsit_preds")


NOTE: Ray Data API for I/O
https://docs.ray.io/en/latest/data/api/input_output.html

Ray Data in Production: 


https://siliconangle.com/2024/10/02/runway-transforming-ai-driven-filmmaking-innovative-tools-techniques-raysummit/

https://raysummit.anyscale.com/flow/anyscale/raysummit2024/landing/page/sessioncatalog/session/1722028596844001bCg0




## Lesson 5:  Ray Serve
notebooks/5_Intro_Serve.ipynb

Ray Serve is a framework for serving ML Applications.

Ray Serve Application is a collection of one or more Deployments that are deployed together


  +-------------------------------------------------------------------------------+
  |                                 Ray Cluster                                   |
  |                                                                               |
  |   +---------------------------------+   +---------------------------------+   |
  |   |            Node 1               |   |            Node N               |   |
  |   | +------------------------+      |   | +------------------------+      |   |
  |   | |    [  Deployment  ]    |-+    |   | |    [  Deployment  ]    |-+    |   |
  |   | |                        | |-+  |   | |                        | |-+  |   |
  |   | | [Replica1] [Replica N] | | |  |   | | [Replica1] [Replica N] | | |  |   |
  |   | |                        | | |  |   | |                        | | |  |   |
  |   | +------------------------+ | |  |   | +------------------------+ | |  |   |
  |   |   +------------------------+ |  |   |   +------------------------+ |  |   |
  |   |     +------------------------+  |   |     +------------------------+  |   |
  |   |                                 |   |                                 |   |
  |   +---------------------------------+   +---------------------------------+   |
  |                                                                               |
  +-------------------------------------------------------------------------------+

 - deployment is fundamental developer element of serve
 - each deployment can have multiple replicas
 - each replica can be configured with a set of compute resources

Use cases: 
 - build end to end ML apps with 
 - scale up / down compute resource to meed demand
 - develop on local machine and scale to multi-node GPU cluster

NOTE:  Serve API is same wheter single node or cluster (changes are resource specific)

Features:
  - response streaming
        https://docs.ray.io/en/latest/serve/tutorials/streaming.html
  - dynamic request batching
        https://docs.ray.io/en/latest/serve/advanced-guides/dyn-req-batch.html
  - multi-node / multi-gpu serving
  - model multiplexing
        https://docs.ray.io/en/latest/serve/model-multiplexing.html
  - fractional compute resource usage
        https://docs.ray.io/en/latest/serve/configure-serve-deployment.html


# Serving an online classifier
NOTE: Main differences are the @server.deployment() decorator and the async def function signagures for __call__ and predict

model: 
!aws s3 cp s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt /mnt/cluster_storage/model.pt


@serve.deployment() # this is the decorator to add
class OnlineMNISTClassifier:
    def __init__(self, local_path: str):
        self.model = torch.jit.load(local_path)
        self.model.to("cuda")
        self.model.eval()

    async def __call__(self, request: Request) -> dict[str, Any]: # __call__ now takes a Starlette Request object
        batch = json.loads(await request.json()) # we will need to parse the JSON body of the request
        return await self.predict(batch)
    
    async def predict(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:
        # same code as OfflineMNISTClassifier.predict except we added async to the method
        images = torch.tensor(batch["image"]).float().to("cuda")

        with torch.no_grad():
            logits = self.model(images).cpu().numpy()

        batch["predicted_label"] = np.argmax(logits, axis=1)
        return batch


# Instantiate classifier as a Ray Serve App using .bind()

mnist_deployment = OnlineMNISTClassifier.options(
    num_replicas=1,
    ray_actor_options={"num_gpus": 1},
)

mnist_app = mnist_deployment.bind(local_path="/mnt/cluster_storage/model.pt")


# Run application
mnist_deployment_handle = serve.run(mnist_app, name='mnist_classifier', blocking=False)

# Test endpoint: here you are using an http post request to test
# 
images = np.random.rand(2, 1, 28, 28).tolist()              # get images
json_request = json.dumps({"image": images})                # build a json request
response = requests.post("http://localhost:8000/", json=json_request)   # send request
response.json()["predicted_label"]                          # get response


# Test gRPC endpoint / Call via API instead of requests
# 
batch = {"image": np.random.rand(10, 1, 28, 28)}
response = await mnist_deployment_handle.predict.remote(batch)
response["predicted_label"]


## Advanced fetures of Ray Serve


1. Fractional compute (GPU) for each deployment replica

mnist_app = OnlineMNISTClassifier.options(
    num_replicas=4,                         # we can scale to up to 10 replicas on a single GPU
    ray_actor_options={"num_gpus": 0.1},    # setting 10% of a GPU
).bind(local_path="/mnt/cluster_storage/model.pt")


# Update running application by running serve.run with the new options.
mnist_deployment_handle = serve.run(mnist_app, name='mnist_classifier', blocking=False)


2. Customizing autoscaling


Can setup autoscaling which is based on target number of ongoing requests

mnist_app = OnlineMNISTClassifier.options(
    ray_actor_options={"num_gpus": 0.1}, 
    autoscaling_config={
        "target_ongoing_requests": 10,
    },
).bind(local_path="/mnt/cluster_storage/model.pt")


Can specify the granularity by setting

- the upscale and downscale delays
- the intervals at which the replica sends metrics reports about the current number of ongoing requests
- the look-back period used to evaluate the current number of ongoing requests

i.e. 


mnist_app = OnlineMNISTClassifier.options(
    ray_actor_options={"num_gpus": 0.1}, 
    autoscaling_config={
        "target_ongoing_requests": 10,
        "upscale_delay_s": 10,
        "downscale_delay_s": 10,
        "metrics_interval_s": 10,
        "look_back_period_s": 10, 
    },
).bind(local_path="/mnt/cluster_storage/model.pt")


Can also set min / max and initial replicase

mnist_app = OnlineMNISTClassifier.options(
    ray_actor_options={"num_gpus": 0.1}, 
    autoscaling_config={
        "target_ongoing_requests": 10,
        "initial_replicas": 0, # scale up from 0 replicas
        "min_replicas": 0,
        "max_replicas": 10,
        # extreme upscale speeds
        "upscale_delay_s": 0,
        "metrics_interval_s": 0.1,
        "look_back_period_s": 0.1,
    },
).bind(local_path="/mnt/cluster_storage/model.pt")





3. Composing deployments

Ray Serve allows composition of Deployments 





## Preprocessor
class OnlineMNISTPreprocessor:
    def __init__(self):
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
        
    async def run(self, batch: dict[str, Any]) -> dict[str, Any]:
        images = batch["image"]
        images = [self.transform(np.array(image, dtype=np.uint8)).cpu().numpy() for image in images]
        return {"image": images}


 # Application ingress that composes OnlineMNISTPreprocessor OnlineMNISTClassifier

@serve.deployment
class ImageServiceIngress: 
    def __init__(self, preprocessor: OnlineMNISTPreprocessor, model: OnlineMNISTClassifier):
        self.preprocessor = preprocessor
        self.model = model

    async def __call__(self, request: Request):
        batch = json.loads(await request.json())
        response = await self.preprocessor.run.remote(batch)
        return await self.model.predict.remote(response)

# Bind image service with preprocessor and classifier
# 
image_classifier_ingress = ImageServiceIngress.bind(
    preprocessor=OnlineMNISTPreprocessor.bind(),
    model=OnlineMNISTClassifier.options(
        num_replicas=1,
        ray_actor_options={"num_gpus": 0.1},
    ).bind(local_path="/mnt/cluster_storage/model.pt"),
)

# Run services
# 
handle = serve.run(image_classifier_ingress, name='image_classifier', blocking=False)

# Test
json_request = json.dumps({"image": image_batch["image"].tolist()}) 
response = requests.post("http://localhost:8000/", json=json_request)
response.json()["predicted_label"]


NOTE:  So what exactly is going on here. 
  1. we set up a Preprocessor class 
  2. next we create an Image Service Ingress class which takes as constructor arguments: 
        a. a pre-processor
        b. a classifier
  3. We instantiate the Image Classifier Intress by binding:  
        a. the pre-processor
        b. the classifier

  4. Then we run the service and receive a handle to it
  5. Lastly we test against the http endpoing





4. Integrate with FastAPI

Integrate FastAPI with Ray Server for: 
 - HTTP routing
 - Pydantic model validation 
 - OpenAPI documentation

use @serve.ingress decorator to designate a FastAPI app as the entrypoint for HTTP requests to our Serve application.

app = FastAPI()

@serve.deployment
@serve.ingress(app)                         # Set FastAPI as ingress
class ImageServiceIngress:
    def __init__(self, preprocessor: OnlineMNISTPreprocessor, model: OnlineMNISTClassifier):
        self.preprocessor = preprocessor
        self.model = model
    
    @app.post("/predict")
    async def predict(self, request: Request):
        batch = json.loads(await request.json())
        response = await self.preprocessor.run.remote(batch)
        out = await self.model.predict.remote(response)
        return {"predicted_label": out["predicted_label"].tolist()}


# Build and run application

image_classifier_ingress = ImageServiceIngress.bind(
    preprocessor=OnlineMNISTPreprocessor.bind(),
    model=OnlineMNISTClassifier.options(
        num_replicas=1,
        ray_actor_options={"num_gpus": 0.1},
    ).bind(local_path="/mnt/cluster_storage/model.pt"),
)

handle = serve.run(image_classifier_ingress, name='image_classifier', blocking=False)

# Test the app
json_request = json.dumps({"image": image_batch["image"].tolist()}) 
response = requests.post("http://localhost:8000/predict", json=json_request)   # Note the /predict route here
response.json()["predicted_label"]


NOTE:  FastAPI comes with OpenAPI (Swagger)



Ray Serve in Production


https://klaviyo.tech/how-klaviyo-built-a-robust-model-serving-platform-with-ray-serve-c02ec65788b3

https://www.samsara.com/blog/building-a-modern-machine-learning-platform-with-ray


KubeRay is open source k8s operator

https://docs.ray.io/en/latest/cluster/kubernetes/getting-started.html#kuberay-quickstart


.